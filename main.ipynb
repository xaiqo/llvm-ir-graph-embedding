{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42b4463d",
   "metadata": {},
   "source": [
    "# Collab settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3392ab10",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1a6d05",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "drive_path = '/content/drive/MyDrive/Inferencja'\n",
    "if os.path.exists(drive_path):\n",
    "    %cd {drive_path}\n",
    "    print(f\"Successfully changed directory to {drive_path}\")\n",
    "else:\n",
    "    print(f\"Error: The directory {drive_path} does not exist.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ff8392",
   "metadata": {},
   "source": [
    "# Imports and Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985dd8ee",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def run(cmd):\n",
    "    print(f\"==> Running: {cmd}\")\n",
    "    ret = subprocess.call(cmd, shell=True)\n",
    "    if ret != 0:\n",
    "        print(f\"Error running command: {cmd}\")\n",
    "        sys.exit(ret)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "286b4d07",
   "metadata": {},
   "source": [
    "# Environment Setup (LLVM 17 + Python Dependencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f390f73",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def setup_environment():\n",
    "    try:\n",
    "        subprocess.check_call(\"llvm-config-17 --version\", shell=True, stdout=subprocess.DEVNULL)\n",
    "        print(\"LLVM 17 already installed.\")\n",
    "    except:\n",
    "        print(\"Installing LLVM 17...\")\n",
    "        run(\"wget https://apt.llvm.org/llvm.sh\")\n",
    "        run(\"chmod +x llvm.sh\")\n",
    "        run(\"sudo ./llvm.sh 17 all\")\n",
    "        # Symlinks\n",
    "        run(\"sudo ln -sf /usr/bin/clang-17 /usr/bin/clang\")\n",
    "        run(\"sudo ln -sf /usr/bin/clang++-17 /usr/bin/clang++\")\n",
    "        run(\"sudo ln -sf /usr/bin/llvm-config-17 /usr/bin/llvm-config\")\n",
    "        run(\"sudo ln -sf /usr/bin/opt-17 /usr/bin/opt\")\n",
    "    \n",
    "    run(\"pip install torch-geometric pytorch-lightning hydra-core wandb transformers datasets scikit-learn\")\n",
    "    run(\"sudo apt-get install -y cmake build-essential\")\n",
    "\n",
    "setup_environment()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad3a5ee",
   "metadata": {},
   "source": [
    "# Build the LLVM GraphExtractor Pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ed4941",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def build_pass():\n",
    "    cwd = os.getcwd()\n",
    "    pass_dir = os.path.join(cwd, \"llvm_pass\")\n",
    "    \n",
    "    if not os.path.exists(pass_dir):\n",
    "        print(\"Error: llvm_pass directory not found. Are you in the project root?\")\n",
    "        sys.exit(1)\n",
    "        \n",
    "    os.chdir(pass_dir)\n",
    "    # Clean build\n",
    "    if os.path.exists(\"build\"):\n",
    "        import shutil\n",
    "        shutil.rmtree(\"build\")\n",
    "        \n",
    "    run(\"chmod +x build.sh\")\n",
    "    run(\"./build.sh\")\n",
    "    os.chdir(cwd)\n",
    "\n",
    "build_pass()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4099c5",
   "metadata": {},
   "source": [
    "# Data Pipeline (Download + Extract Graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59be4ba4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def run_pipeline():    \n",
    "    # Download POJ-104\n",
    "    run(\"python3 data_pipeline/download_poj104.py\")\n",
    "    \n",
    "    # Compile & Extract (Regenerate Data)\n",
    "    print(\"Generating TOON graphs from C++ sources...\")\n",
    "    input_dir = \"data/raw/poj104/val\"\n",
    "    output_dir = \"data/processed/val\"\n",
    "    \n",
    "    if os.path.exists(output_dir):\n",
    "        import shutil\n",
    "        shutil.rmtree(output_dir)\n",
    "    \n",
    "    env_vars = f\"PYTHONPATH={os.getcwd()}\"\n",
    "    run(f\"{env_vars} python3 data_pipeline/compile_and_extract.py --input {input_dir} --output {output_dir} --jobs 4 --optimize\")\n",
    "\n",
    "run_pipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a4cc83",
   "metadata": {},
   "source": [
    "# Train the Hybrid GNN + BERT Model (GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9151d9dc",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!PYTHONPATH=. python3 ml_core/train.py model.data_dir=data/processed/val/graphs model.use_bert=True model.batch_size=32 train.epochs=5 +trainer.accelerator=gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd118bb",
   "metadata": {},
   "source": [
    "# Generate t-SNE visualisation for GNN + BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b2d374",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!PYTHONPATH=. python3 ml_core/visualize.py --ckpt \"lightning_logs/*/checkpoints/*.ckpt\" --data data/processed/val/graphs --output tsne_result.png"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a64419d",
   "metadata": {},
   "source": [
    "# Train the Baseline (No CodeBERT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be2ac3c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!PYTHONPATH=. python3 ml_core/train.py model.data_dir=data/processed/val/graphs   model.use_bert=False   model.batch_size=64   train.epochs=5   hydra.run.dir=outputs/baseline +trainer.accelerator=gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c59268",
   "metadata": {},
   "source": [
    "# Generate t-SNE visualisation for Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24645632",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!PYTHONPATH=. python3 ml_core/visualize.py --ckpt \"outputs/baseline/lightning_logs/*/checkpoints/*.ckpt\" --data data/processed/val/graphs  --output tsne_baseline.png"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77b0435",
   "metadata": {},
   "source": [
    "# Comparission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accfe872",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!PYTHONPATH=. python3 ml_core/visualize.py  --ckpt \"lightning_logs/*/checkpoints/*.ckpt\" --data data/processed/val/graphs  --output tsne_hybrid.png"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
